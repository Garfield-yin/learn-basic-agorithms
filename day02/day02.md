# 如何分析、统计算法的执行效率和资源消耗？

### 为什么要进行复杂度分析
把代码执行一遍内存占用和速度就出来了，这种方式叫做事后统计法，这种方法有很大的局限性。
 1. 测试结果非常依赖运行环境
 2. 测试结果受数据规模影响很大

 所以我们需要一种不依赖测试，就能够估算算法执行效率的方法。这种方法就是复杂度分析。


### 大 O 复杂度表示方法

 分析举例：

 ```

 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
 ```

 从 CPU 的角度看，每一行代码执行的过程是：读取-运算-写数据。粗略假设每一行代码执行时间都一样，为 unit_time, 那么这段代码的总执行时间是：
T(n) = (2n+2)*unit_time, 从这个表达式看，得出一个结论：
所有代码的执行时间T(n)与每行代码的的执行次数成正比。

把这个规律总结为一个统一的表达式：
T(n) = O(f(n))

T(n): 代码的总执行时间
n: 数据规模的大小
f(n): 代码的执行次数总和
O:表示代码的执行时间 T(n) 与f(n) 表达式成正比。
上述代码可以表示为：
T(n) = O(2n+2)
但是：
大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势。
这叫做渐进时间复杂度，或者时间复杂度。

既然是变化趋势，反应的是一个量级，通常会忽略公式中的常量、低阶、系数，只需要记录一个最大的量级即可。
所以在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。

上一段代码中，执行次数最多的是4，5行，忽略常量，所以总的时间复杂度可以表达为 O(n).

总结为以下原则：
1. 只关注循环执行次数最多的一段代码
2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

### 常见的时间复杂度分析
![](./常见时间复杂度量级.jpg)


1. O(1)
只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。
2. O(logn)、O(nlogn)
```
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
 ```
![](./logn.jpg)
表达式求解：
2x=n
n = log2n
所有对数阶的时间复杂度都记为 O(logn)。
因为在采用大 O 标记复杂度的时候，可以忽略系数。

3. O(m+n)、O(m*n)

 ```
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
 ```

 时间复杂度：
 O(m+n)


### 空间复杂度
 表示算法的存储空间与数据规模之间的增长关系。

 ```

void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
 ```

 与时间复杂度分析一样，这段代码空间复杂度也为 O(n)。
